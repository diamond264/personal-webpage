+++
widget = "blank"
headless = true
active = true
weight = 20

title = "Publications"
subtitle = ""

[design]
  # Choose how many columns the section has. Valid values: 1 or 2.
  columns = "1"
[design.spacing]
  padding = ["15px", "0", "25px", "0"]
+++
<style>
h2.publications {
  text-align: center;
}
div.pub {
  font-size: 13pt;
  margin-left: 15%;
  margin-right: 15%;
  margin-bottom: 20px;
  width: 70%;
}
a.title {
  font-size: 14pt;
  font-weight: bold;
}
@media only screen and (max-width: 992px) {
div.pub {
  font-size: 12pt;
  margin-left: 0%;
  margin-right: 0%;
  margin-bottom: 20px;
  width: 100%;
}
a.title {
  font-size: 13pt;
  font-weight: bold;
}
}
</style>
<h2 class="publications">Preprints &amp; Under Review</h2>

<div class="pub">
<a class="title" href="https://arxiv.org/abs/2404.15305">"Adapt^2: Adapting Pre-Trained Sensing Models to End-Users via Self-Supervision Replay"</a> </br>
<strong style="text-decoration:underline">Hyungjun Yoon</strong>, Jaehyun Kwak, Biniyam Aschalew Tolera, Gaole Dai, Mo Li, Taesik Gong, Kimin Lee, and Sung-Ju Lee</br>
<i>arXiv preprint</i></br>
<a class="badge badge-info" href="papers/Adapt2.pdf">{{< icon name="book" pack="fas" >}} pdf</a>
<a class="badge badge-info" href="https://arxiv.org/abs/2404.15305">{{< icon name="link" pack="fas" >}} arXiv</a>
</div>

<div class="pub">
<a class="title" href="https://arxiv.org/abs/2209.00945">"IMG2IMU: Applying Knowledge from Large-Scale Images to IMU Applications via Contrastive Learning"</a></br>
<strong style="text-decoration:underline">Hyungjun Yoon</strong>, Hyeongheon Cha, Canh Hoang Nguyen, Taesik Gong, and Sung-Ju Lee</br>
<i>Under review</i></br>
<a class="badge badge-info" href="papers/IMG2IMU.pdf">{{< icon name="book" pack="fas" >}} pdf</a>
<a class="badge badge-info" href="https://arxiv.org/abs/2209.00945">{{< icon name="link" pack="fas" >}} arXiv</a>
</div>

<div class="pub">
<a class="title" href=".">""I know my personal data does not leave my phone, but ...": Understanding User (Mis)Perceptions of On-Device AI Voice Phishing Detection"</a> </br>
Subin Park, <strong style="text-decoration:underline">Hyungjun Yoon</strong>, Hyoungshick Kim, and Sung-Ju Lee</br>
<i>Under review</i></br>
</div>

<div class="pub">
<a class="title" href=".">"Recover as It is Designed to Be: Recovering from Compatibility Mobile App Crashes by Reusing User Flows"</a> </br>
Donghwi Kim, <strong style="text-decoration:underline">Hyungjun Yoon</strong>, Chang Min Park, Sujin Han, Youngjin Kwon, Steve Ko, and Sung-Ju Lee</br>
<i>arXiv preprint</i></br>
<a class="badge badge-info" href="papers/SecondChance.pdf">{{< icon name="book" pack="fas" >}} pdf</a>
<a class="badge badge-info" href="https://arxiv.org/abs/2406.01339">{{< icon name="link" pack="fas" >}} arXiv</a>
</div>

<h2 class="publications">Conferences and Journals</h2>

<div class="pub">
"ContrastSense: Domain-invariant Contrastive Learning for In-the-wild Wearable Sensing" </br>
Gaole Dai, Huatao Xu, <strong style="text-decoration:underline">Hyungjun Yoon</strong>, Sung-Ju Lee, Rui Tan, and Mo Li</br>
<i><b>UbiComp 2025</b></i></br>
<!-- <a class="badge badge-info" href="papers/ContrastSense.pdf">{{< icon name="book" pack="fas" >}} pdf</a> -->
</div>

<div class="pub">
<a class="title" href="https://arxiv.org/abs/2407.10385">"By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting"</a> </br>
<strong style="text-decoration:underline">Hyungjun Yoon</strong>, Biniyam Aschalew Tolera, Taesik Gong, Kimin Lee, Sung-Ju Lee</br>
<i><b>EMNLP 2024 (main track, long paper)</b></i></br>
<a class="badge badge-info" href="papers/ByMyEyes.pdf">{{< icon name="book" pack="fas" >}} pdf</a>
<a class="badge badge-info" href="https://arxiv.org/abs/2407.10385">{{< icon name="link" pack="fas" >}} arXiv</a>
</div>

<div class="pub">
<a class="title" href="https://dl.acm.org/doi/abs/10.1145/3491102.3502041">"FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning"</a> </br>
Jaemin Shin, <strong style="text-decoration:underline">Hyungjun Yoon</strong>, Seungjoo Lee, Sungjoon Park, Yunxin Liu, Jinho D. Choi, and Sung-Ju Lee</br>
<i><b>EMNLP 2023 (main track, short paper)</b></i></br>
<a class="badge badge-info" href="papers/Fedtherapist.pdf">{{< icon name="book" pack="fas" >}} pdf</a>
<a class="badge badge-info" href="https://nmsl.kaist.ac.kr/projects/fedtherapist/">{{< icon name="link" pack="fas" >}} website</a>
<!-- <a class="badge badge-info" href="https://www.youtube.com/watch?v=77XNl39QoEE&feature=youtu.be">{{< icon name="video" pack="fas" >}} video</a> -->
</div>

<div class="pub">
<a class="title" href="https://dl.acm.org/doi/abs/10.1145/3491102.3502041">"MyDJ: Sensing Food Intakes with an Attachable on Your Eyeglass Frame"</a> </br>
Jaemin Shin, Seungjoo Lee, Taesik Gong, <strong style="text-decoration:underline">Hyungjun Yoon</strong>, Hyunchul Roh, Andrea Bianchi, and Sung-Ju Lee</br>
<i><b>CHI 2022</b></i></br>
<a class="badge badge-info" href="papers/MyDJ.pdf">{{< icon name="book" pack="fas" >}} pdf</a>
<a class="badge badge-info" href="https://nmsl.kaist.ac.kr/projects/mydj/">{{< icon name="link" pack="fas" >}} website</a>
<a class="badge badge-info" href="https://www.youtube.com/watch?v=77XNl39QoEE&feature=youtu.be">{{< icon name="video" pack="fas" >}} video</a>
<a class="badge badge-info">{{< icon name="award" pack="fas" >}} Honorable Mention Award</a>
</div>